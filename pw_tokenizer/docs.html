

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pw_tokenizer &mdash; Pigweed</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="pw_toolchain" href="../pw_toolchain/docs.html" />
    <link rel="prev" title="Go" href="../pw_target_runner/go/docs.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Pigweed
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pigweed.googlesource.com/pigweed/pigweed/+/refs/heads/master">Source Code</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pigweed-review.googlesource.com">Code Reviews</a></li>
<li class="toctree-l1"><a class="reference external" href="https://groups.google.com/forum/#!forum/pigweed">Mailing List</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discord.gg/M9NSeTA">Chat Room</a></li>
<li class="toctree-l1"><a class="reference external" href="https://bugs.chromium.org/p/pigweed/issues/list">Issue Tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CODE_OF_CONDUCT.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/embedded_cpp_guide.html">Embedded C++ Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/style_guide.html">Code Style</a></li>
<li class="toctree-l1"><a class="reference internal" href="../targets.html">Targets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build_system.html">Build System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/module_structure.html">Module Structure</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../module_guides.html">Module Guides</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../docker/docs.html">docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_allocator/docs.html">pw_allocator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_arduino_build/docs.html">pw_arduino_build</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_assert/docs.html">pw_assert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_assert_basic/docs.html">pw_assert_basic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_assert_log/docs.html">pw_assert_log</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_base64/docs.html">pw_base64</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_bloat/docs.html">pw_bloat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_blob_store/docs.html">pw_blob_store</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_boot_armv7m/docs.html">pw_boot_armv7m</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_build/docs.html">pw_build</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_bytes/docs.html">pw_bytes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_checksum/docs.html">pw_checksum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_cli/docs.html">pw_cli</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_containers/docs.html">pw_containers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_cpu_exception/docs.html">pw_cpu_exception</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_cpu_exception_armv7m/docs.html">pw_cpu_exception_armv7m</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_docgen/docs.html">pw_docgen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_doctor/docs.html">pw_doctor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_env_setup/docs.html">pw_env_setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_fuzzer/docs.html">pw_fuzzer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_hdlc_lite/docs.html">pw_hdlc_lite</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_hex_dump/docs.html">pw_hex_dump</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_kvs/docs.html">pw_kvs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_log/docs.html">pw_log</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_log_basic/docs.html">pw_log_basic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_log_null/docs.html">pw_log_null</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_log_rpc/docs.html">pw_log_rpc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_log_tokenized/docs.html">pw_log_tokenized</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_metric/docs.html">pw_metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_minimal_cpp_stdlib/docs.html">pw_minimal_cpp_stdlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_module/docs.html">pw_module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_polyfill/docs.html">pw_polyfill</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_preprocessor/docs.html">pw_preprocessor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_presubmit/docs.html">pw_presubmit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_protobuf/docs.html">pw_protobuf</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_protobuf_compiler/docs.html">pw_protobuf_compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_random/docs.html">pw_random</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_result/docs.html">pw_result</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_ring_buffer/docs.html">pw_ring_buffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_rpc/docs.html">pw_rpc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_span/docs.html">pw_span</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_status/docs.html">pw_status</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_stream/docs.html">pw_stream</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_string/docs.html">pw_string</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_sys_io/docs.html">pw_sys_io</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_sys_io_arduino/docs.html">pw_sys_io_arduino</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_sys_io_baremetal_stm32f429/docs.html">pw_sys_io_baremetal_stm32f429</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_sys_io_stdio/docs.html">pw_sys_io_stdio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_target_runner/docs.html">pw_target_runner</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">pw_tokenizer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-overview">Basic overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#example-tokenized-logging">Example: tokenized logging</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#getting-started">Getting started</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tokenization">Tokenization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tokenization-macros">Tokenization macros</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tokenizing-function-names">Tokenizing function names</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tokenization-in-python">Tokenization in Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="#encoding">Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="#token-generation-fixed-length-hashing-at-compile-time">Token generation: fixed length hashing at compile time</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tokenization-domains">Tokenization domains</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#token-databases">Token databases</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#csv-database-format">CSV database format</a></li>
<li class="toctree-l4"><a class="reference internal" href="#binary-database-format">Binary database format</a></li>
<li class="toctree-l4"><a class="reference internal" href="#managing-token-databases">Managing token databases</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#detokenization">Detokenization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#python">Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="#c">C++</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#base64-format">Base64 format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decoding">Decoding</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#deployment-war-story">Deployment war story</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#results">Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#firmware-deployment">Firmware deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#database-management">Database management</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decoding-tooling-deployment">Decoding tooling deployment</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#limitations-and-future-work">Limitations and future work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#gcc-bug-tokenization-in-template-functions">GCC bug: tokenization in template functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bit-tokenization">64-bit tokenization</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tokenization-in-headers">Tokenization in headers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tokenized-strings-as-s-arguments">Tokenized strings as <code class="docutils literal notranslate"><span class="pre">%s</span></code> arguments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#compatibility">Compatibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dependencies">Dependencies</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../pw_toolchain/docs.html">pw_toolchain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_trace/docs.html">pw_trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_trace_tokenized/docs.html">pw_trace_tokenized</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_unit_test/docs.html">pw_unit_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_varint/docs.html">pw_varint</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_watch/docs.html">pw_watch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pw_web_ui/docs.html">pw_web_ui</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Pigweed</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../module_guides.html">Module Guides</a> &raquo;</li>
        
      <li>pw_tokenizer</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pw-tokenizer">
<span id="module-pw-tokenizer"></span><h1>pw_tokenizer<a class="headerlink" href="#pw-tokenizer" title="Permalink to this headline">¶</a></h1>
<p>Logging is critical, but developers are often forced to choose between
additional logging or saving crucial flash space. The <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> module
helps address this by replacing printf-style strings with binary tokens during
compilation. This enables extensive logging with substantially less memory
usage.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This usage of the term “tokenizer” is not related to parsing! The
module is called tokenizer because it replaces a whole string literal with an
integer token. It does not parse strings into separate tokens.</p>
</div>
<p>The most common application of <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> is binary logging, and it is
designed to integrate easily into existing logging systems. However, the
tokenizer is general purpose and can be used to tokenize any strings, with or
without printf-style arguments.</p>
<p><strong>Why tokenize strings?</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>Dramatically reduce binary size by removing string literals from binaries.</p></li>
<li><p>Reduce I/O traffic, RAM, and flash usage by sending and storing compact
tokens instead of strings. We’ve seen over 50% reduction in encoded log
contents.</p></li>
<li><p>Reduce CPU usage by replacing snprintf calls with simple tokenization code.</p></li>
<li><p>Remove potentially sensitive log, assert, and other strings from binaries.</p></li>
</ul>
</div></blockquote>
<div class="section" id="basic-overview">
<h2>Basic overview<a class="headerlink" href="#basic-overview" title="Permalink to this headline">¶</a></h2>
<p>There are two sides to <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code>, which we call tokenization and
detokenization.</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Tokenization</strong> converts string literals in the source code to
binary tokens at compile time. If the string has printf-style arguments,
these are encoded to compact binary form at runtime.</p></li>
<li><p><strong>Detokenization</strong> converts tokenized strings back to the original
human-readable strings.</p></li>
</ul>
</div></blockquote>
<p>Here’s an overview of what happens when <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> is used:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>During compilation, the <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> module hashes string literals to
generate stable 32-bit tokens.</p></li>
<li><p>The tokenization macro removes these strings by declaring them in an ELF
section that is excluded from the final binary.</p></li>
<li><p>After compilation, strings are extracted from the ELF to build a database
of tokenized strings for use by the detokenizer. The ELF file may also be
used directly.</p></li>
<li><p>During operation, the device encodes the string token and its arguments, if
any.</p></li>
<li><p>The encoded tokenized strings are sent off-device or stored.</p></li>
<li><p>Off-device, the detokenizer tools use the token database to decode the
strings to human-readable form.</p></li>
</ol>
</div></blockquote>
<div class="section" id="example-tokenized-logging">
<h3>Example: tokenized logging<a class="headerlink" href="#example-tokenized-logging" title="Permalink to this headline">¶</a></h3>
<p>This example demonstrates using <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> for logging. In this example,
tokenized logging saves ~90% in binary size (41 → 4 bytes) and 70% in encoded
size (49 → 15 bytes).</p>
<p><strong>Before</strong>: plain text logging</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 24%" />
<col style="width: 57%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Location</p></th>
<th class="head"><p>Logging Content</p></th>
<th class="head"><p>Size in bytes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Source contains</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">LOG(&quot;Battery</span> <span class="pre">state:</span> <span class="pre">%s;</span> <span class="pre">battery</span>
<span class="pre">voltage:</span> <span class="pre">%d</span> <span class="pre">mV&quot;,</span> <span class="pre">state,</span> <span class="pre">voltage);</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Binary contains</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&quot;Battery</span> <span class="pre">state:</span> <span class="pre">%s;</span> <span class="pre">battery</span>
<span class="pre">voltage:</span> <span class="pre">%d</span> <span class="pre">mV&quot;</span></code></p></td>
<td><p>41</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>(log statement is called with
<code class="docutils literal notranslate"><span class="pre">&quot;CHARGING&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">3989</span></code> as arguments)</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Device transmits</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&quot;Battery</span> <span class="pre">state:</span> <span class="pre">CHARGING;</span> <span class="pre">battery</span>
<span class="pre">voltage:</span> <span class="pre">3989</span> <span class="pre">mV&quot;</span></code></p></td>
<td><p>49</p></td>
</tr>
<tr class="row-even"><td><p>When viewed</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&quot;Battery</span> <span class="pre">state:</span> <span class="pre">CHARGING;</span> <span class="pre">battery</span>
<span class="pre">voltage:</span> <span class="pre">3989</span> <span class="pre">mV&quot;</span></code></p></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>After</strong>: tokenized logging</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 21%" />
<col style="width: 69%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Location</p></th>
<th class="head"><p>Logging Content</p></th>
<th class="head"><p>Size in
bytes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Source contains</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">LOG(&quot;Battery</span> <span class="pre">state:</span> <span class="pre">%s;</span> <span class="pre">battery</span>
<span class="pre">voltage:</span> <span class="pre">%d</span> <span class="pre">mV&quot;,</span> <span class="pre">state,</span> <span class="pre">voltage);</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Binary contains</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">d9</span> <span class="pre">28</span> <span class="pre">47</span> <span class="pre">8e</span></code> (0x8e4728d9)</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>(log statement is called with
<code class="docutils literal notranslate"><span class="pre">&quot;CHARGING&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">3989</span></code> as arguments)</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Device transmits</p></td>
<td><table class="docutils align-default">
<colgroup>
<col style="width: 27%" />
<col style="width: 55%" />
<col style="width: 18%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">d9</span> <span class="pre">28</span> <span class="pre">47</span> <span class="pre">8e</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">08</span> <span class="pre">43</span> <span class="pre">48</span> <span class="pre">41</span> <span class="pre">52</span> <span class="pre">47</span> <span class="pre">49</span> <span class="pre">4E</span> <span class="pre">47</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">aa</span> <span class="pre">3e</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Token</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&quot;CHARGING&quot;</span></code> argument</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">3989</span></code>,
as
varint</p></td>
</tr>
</tbody>
</table>
</td>
<td><p>15</p></td>
</tr>
<tr class="row-odd"><td><p>When viewed</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&quot;Battery</span> <span class="pre">state:</span> <span class="pre">CHARGING;</span> <span class="pre">battery</span> <span class="pre">voltage:</span> <span class="pre">3989</span> <span class="pre">mV&quot;</span></code></p></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="getting-started">
<h2>Getting started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<p>Integrating <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> requires a few steps beyond building the code. This
section describes one way <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> might be integrated with a project.
These steps can be adapted as needed.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Add <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> to your build. Build files for GN, CMake, and Bazel
are provided. For Make or other build systems, add the files specified in
the BUILD.gn’s <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> target to the build.</p></li>
<li><p>Use the tokenization macros in your code. See <a class="reference internal" href="#tokenization">Tokenization</a>.</p></li>
<li><p>Add the contents of <code class="docutils literal notranslate"><span class="pre">pw_tokenizer_linker_sections.ld</span></code> to your project’s
linker script.</p></li>
<li><p>Compile your code to produce an ELF file.</p></li>
<li><p>Run <code class="docutils literal notranslate"><span class="pre">database.py</span> <span class="pre">create</span></code> on the ELF file to generate a CSV token
database. See <a class="reference internal" href="#managing-token-databases">Managing token databases</a>.</p></li>
<li><p>Commit the token database to your repository. See notes in <a class="reference internal" href="#database-management">Database
management</a>.</p></li>
<li><p>Integrate a <code class="docutils literal notranslate"><span class="pre">database.py</span> <span class="pre">add</span></code> command to your build to automatically
update the committed token database. See <a class="reference internal" href="#update-a-database">Update a database</a>.</p></li>
<li><p>Integrate <code class="docutils literal notranslate"><span class="pre">detokenize.py</span></code> or the C++ detokenization library with your
tools to decode tokenized logs. See <a class="reference internal" href="#detokenization">Detokenization</a>.</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="tokenization">
<h2>Tokenization<a class="headerlink" href="#tokenization" title="Permalink to this headline">¶</a></h2>
<p>Tokenization converts a string literal to a token. If it’s a printf-style
string, its arguments are encoded along with it. The results of tokenization can
be sent off device or stored in place of a full string.</p>
<div class="section" id="tokenization-macros">
<h3>Tokenization macros<a class="headerlink" href="#tokenization-macros" title="Permalink to this headline">¶</a></h3>
<p>Adding tokenization to a project is simple. To tokenize a string, include
<code class="docutils literal notranslate"><span class="pre">pw_tokenizer/tokenize.h</span></code> and invoke one of the <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_</span></code> macros.</p>
<div class="section" id="tokenize-a-string-literal">
<h4>Tokenize a string literal<a class="headerlink" href="#tokenize-a-string-literal" title="Permalink to this headline">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_STRING</span></code> macro converts a string literal to a <code class="docutils literal notranslate"><span class="pre">uint32_t</span></code>
token.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">constexpr</span> <span class="kt">uint32_t</span> <span class="n">token</span> <span class="o">=</span> <span class="n">PW_TOKENIZE_STRING</span><span class="p">(</span><span class="s">&quot;Any string literal!&quot;</span><span class="p">);</span>
</pre></div>
</div>
<div class="admonition-when-to-use-this-macro admonition">
<p class="admonition-title">When to use this macro</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_STRING</span></code> to tokenize string literals that do not have
%-style arguments.</p>
</div>
</div>
<div class="section" id="tokenize-to-a-handler-function">
<h4>Tokenize to a handler function<a class="headerlink" href="#tokenize-to-a-handler-function" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_GLOBAL_HANDLER</span></code> is the most efficient tokenization function,
since it takes the fewest arguments. It encodes a tokenized string to a
buffer on the stack. The size of the buffer is set with
<code class="docutils literal notranslate"><span class="pre">PW_TOKENIZER_CFG_ENCODING_BUFFER_SIZE_BYTES</span></code>.</p>
<p>This macro is provided by the <code class="docutils literal notranslate"><span class="pre">pw_tokenizer:global_handler</span></code> facade. The
backend for this facade must define the <code class="docutils literal notranslate"><span class="pre">pw_tokenizer_HandleEncodedMessage</span></code>
C-linkage function.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">PW_TOKENIZE_TO_GLOBAL_HANDLER</span><span class="p">(</span><span class="n">format_string_literal</span><span class="p">,</span> <span class="n">arguments</span><span class="p">...);</span>

<span class="kt">void</span> <span class="nf">pw_tokenizer_HandleEncodedMessage</span><span class="p">(</span><span class="k">const</span> <span class="kt">uint8_t</span> <span class="n">encoded_message</span><span class="p">[],</span>
                                       <span class="kt">size_t</span> <span class="n">size_bytes</span><span class="p">);</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_GLOBAL_HANDLER_WITH_PAYLOAD</span></code> is similar, but passes a
<code class="docutils literal notranslate"><span class="pre">uintptr_t</span></code> argument to the global handler function. Values like a log level
can be packed into the <code class="docutils literal notranslate"><span class="pre">uintptr_t</span></code>.</p>
<p>This macro is provided by the <code class="docutils literal notranslate"><span class="pre">pw_tokenizer:global_handler_with_payload</span></code>
facade. The backend for this facade must define the
<code class="docutils literal notranslate"><span class="pre">pw_tokenizer_HandleEncodedMessageWithPayload</span></code> C-linkage function.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">PW_TOKENIZE_TO_GLOBAL_HANDLER_WITH_PAYLOAD</span><span class="p">(</span><span class="n">payload</span><span class="p">,</span>
                                           <span class="n">format_string_literal</span><span class="p">,</span>
                                           <span class="n">arguments</span><span class="p">...);</span>

<span class="kt">void</span> <span class="nf">pw_tokenizer_HandleEncodedMessageWithPayload</span><span class="p">(</span>
    <span class="kt">uintptr_t</span> <span class="n">payload</span><span class="p">,</span> <span class="k">const</span> <span class="kt">uint8_t</span> <span class="n">encoded_message</span><span class="p">[],</span> <span class="kt">size_t</span> <span class="n">size_bytes</span><span class="p">);</span>
</pre></div>
</div>
<div class="admonition-when-to-use-these-macros admonition">
<p class="admonition-title">When to use these macros</p>
<p>Use anytime a global handler is sufficient, particularly for widely expanded
macros, like a logging macro. <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_GLOBAL_HANDLER</span></code> or
<code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_GLOBAL_HANDLER_WITH_PAYLOAD</span></code> are the most efficient macros
for tokenizing printf-style strings.</p>
</div>
</div>
<div class="section" id="tokenize-to-a-callback">
<h4>Tokenize to a callback<a class="headerlink" href="#tokenize-to-a-callback" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_CALLBACK</span></code> tokenizes to a buffer on the stack and calls a
<code class="docutils literal notranslate"><span class="pre">void(const</span> <span class="pre">uint8_t*</span> <span class="pre">buffer,</span> <span class="pre">size_t</span> <span class="pre">buffer_size)</span></code> callback that is provided at
the call site. The size of the buffer is set with
<code class="docutils literal notranslate"><span class="pre">PW_TOKENIZER_CFG_ENCODING_BUFFER_SIZE_BYTES</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">PW_TOKENIZE_TO_CALLBACK</span><span class="p">(</span><span class="n">HandlerFunction</span><span class="p">,</span> <span class="s">&quot;Format string: %x&quot;</span><span class="p">,</span> <span class="n">arguments</span><span class="p">...);</span>
</pre></div>
</div>
<div class="admonition-when-to-use-this-macro admonition">
<p class="admonition-title">When to use this macro</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_CALLBACK</span></code> if the global handler version is already in
use for another purpose or more flexibility is needed.</p>
</div>
</div>
<div class="section" id="tokenize-to-a-buffer">
<h4>Tokenize to a buffer<a class="headerlink" href="#tokenize-to-a-buffer" title="Permalink to this headline">¶</a></h4>
<p>The most flexible tokenization macro is <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_BUFFER</span></code>, which encodes
to a caller-provided buffer.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">uint8_t</span> <span class="n">buffer</span><span class="p">[</span><span class="n">BUFFER_SIZE</span><span class="p">];</span>
<span class="kt">size_t</span> <span class="n">size_bytes</span> <span class="o">=</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">);</span>
<span class="n">PW_TOKENIZE_TO_BUFFER</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">size_bytes</span><span class="p">,</span> <span class="n">format_string_literal</span><span class="p">,</span> <span class="n">arguments</span><span class="p">...);</span>
</pre></div>
</div>
<p>While <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_BUFFER</span></code> is maximally flexible, it takes more arguments
than the other macros, so its per-use code size overhead is larger.</p>
<div class="admonition-when-to-use-this-macro admonition">
<p class="admonition-title">When to use this macro</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_BUFFER</span></code> to encode to a custom-sized buffer or if the
other macros are insufficient. Avoid using <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_BUFFER</span></code> in
widely expanded macros, such as a logging macro, because it will result in
larger code size than its alternatives.</p>
</div>
</div>
<div class="section" id="example-binary-logging">
<h4>Example: binary logging<a class="headerlink" href="#example-binary-logging" title="Permalink to this headline">¶</a></h4>
<p>String tokenization is perfect for logging. Consider the following log macro,
which gathers the file, line number, and log message. It calls the <code class="docutils literal notranslate"><span class="pre">RecordLog</span></code>
function, which formats the log string, collects a timestamp, and transmits the
result.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#define LOG_INFO(format, ...) \</span>
<span class="cp">    RecordLog(LogLevel_INFO, __FILE_NAME__, __LINE__, format, ##__VA_ARGS__)</span>

<span class="kt">void</span> <span class="nf">RecordLog</span><span class="p">(</span><span class="n">LogLevel</span> <span class="n">level</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">file</span><span class="p">,</span> <span class="kt">int</span> <span class="n">line</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">format</span><span class="p">,</span>
               <span class="p">...)</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">level</span> <span class="o">&lt;</span> <span class="n">current_log_level</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="kt">int</span> <span class="n">bytes</span> <span class="o">=</span> <span class="n">snprintf</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">),</span> <span class="s">&quot;%s:%d &quot;</span><span class="p">,</span> <span class="n">file</span><span class="p">,</span> <span class="n">line</span><span class="p">);</span>

  <span class="kt">va_list</span> <span class="n">args</span><span class="p">;</span>
  <span class="n">va_start</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">format</span><span class="p">);</span>
  <span class="n">bytes</span> <span class="o">+=</span> <span class="n">vsnprintf</span><span class="p">(</span><span class="o">&amp;</span><span class="n">buffer</span><span class="p">[</span><span class="n">bytes</span><span class="p">],</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">buffer</span><span class="p">)</span> <span class="o">-</span> <span class="n">bytes</span><span class="p">,</span> <span class="n">format</span><span class="p">,</span> <span class="n">args</span><span class="p">);</span>
  <span class="n">va_end</span><span class="p">(</span><span class="n">args</span><span class="p">);</span>

  <span class="n">TransmitLog</span><span class="p">(</span><span class="n">TimeSinceBootMillis</span><span class="p">(),</span> <span class="n">buffer</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>It is trivial to convert this to a binary log using the tokenizer. The
<code class="docutils literal notranslate"><span class="pre">RecordLog</span></code> call is replaced with a
<code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_GLOBAL_HANDLER_WITH_PAYLOAD</span></code> invocation. The
<code class="docutils literal notranslate"><span class="pre">pw_tokenizer_HandleEncodedMessageWithPayload</span></code> implementation collects the
timestamp and transmits the message with <code class="docutils literal notranslate"><span class="pre">TransmitLog</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#define LOG_INFO(format, ...)                   \</span>
<span class="cp">    PW_TOKENIZE_TO_GLOBAL_HANDLER_WITH_PAYLOAD( \</span>
<span class="cp">        (pw_tokenizer_Payload)LogLevel_INFO,    \</span>
<span class="cp">        __FILE_NAME__ &quot;:%d &quot; format,            \</span>
<span class="cp">        __LINE__,                               \</span>
<span class="cp">        __VA_ARGS__);                           \</span>

<span class="k">extern</span> <span class="s">&quot;C&quot;</span> <span class="kt">void</span> <span class="n">pw_tokenizer_HandleEncodedMessageWithPayload</span><span class="p">(</span>
    <span class="kt">uintptr_t</span> <span class="n">level</span><span class="p">,</span> <span class="k">const</span> <span class="kt">uint8_t</span> <span class="n">encoded_message</span><span class="p">[],</span> <span class="kt">size_t</span> <span class="n">size_bytes</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="n">LogLevel</span><span class="o">&gt;</span><span class="p">(</span><span class="n">level</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">current_log_level</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">TransmitLog</span><span class="p">(</span><span class="n">TimeSinceBootMillis</span><span class="p">(),</span> <span class="n">encoded_message</span><span class="p">,</span> <span class="n">size_bytes</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">__FILE_NAME__</span></code> string is directly included in the log format
string. Since the string is tokenized, this has no effect on binary size. A
<code class="docutils literal notranslate"><span class="pre">%d</span></code> for the line number is added to the format string, so that changing the
line of the log message does not generate a new token. There is no overhead for
additional tokens, but it may not be desirable to fill a token database with
duplicate log lines.</p>
</div>
</div>
<div class="section" id="tokenizing-function-names">
<h3>Tokenizing function names<a class="headerlink" href="#tokenizing-function-names" title="Permalink to this headline">¶</a></h3>
<p>The string literal tokenization functions support tokenizing string literals or
constexpr character arrays (<code class="docutils literal notranslate"><span class="pre">constexpr</span> <span class="pre">const</span> <span class="pre">char[]</span></code>). In GCC and Clang, the
special <code class="docutils literal notranslate"><span class="pre">__func__</span></code> variable and <code class="docutils literal notranslate"><span class="pre">__PRETTY_FUNCTION__</span></code> extension are declared
as <code class="docutils literal notranslate"><span class="pre">static</span> <span class="pre">constexpr</span> <span class="pre">char[]</span></code> in C++ instead of the standard <code class="docutils literal notranslate"><span class="pre">static</span> <span class="pre">const</span>
<span class="pre">char[]</span></code>. This means that <code class="docutils literal notranslate"><span class="pre">__func__</span></code> and <code class="docutils literal notranslate"><span class="pre">__PRETTY_FUNCTION__</span></code> can be
tokenized while compiling C++ with GCC or Clang.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Tokenize the special function name variables.</span>
<span class="k">constexpr</span> <span class="kt">uint32_t</span> <span class="n">function</span> <span class="o">=</span> <span class="n">PW_TOKENIZE_STRING</span><span class="p">(</span><span class="n">__func__</span><span class="p">);</span>
<span class="k">constexpr</span> <span class="kt">uint32_t</span> <span class="n">pretty_function</span> <span class="o">=</span> <span class="n">PW_TOKENIZE_STRING</span><span class="p">(</span><span class="n">__PRETTY_FUNCTION__</span><span class="p">);</span>

<span class="c1">// Tokenize the function name variables to a handler function.</span>
<span class="n">PW_TOKENIZE_TO_GLOBAL_HANDLER</span><span class="p">(</span><span class="n">__func__</span><span class="p">)</span>
<span class="n">PW_TOKENIZE_TO_GLOBAL_HANDLER</span><span class="p">(</span><span class="n">__PRETTY_FUNCTION__</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">__func__</span></code> and <code class="docutils literal notranslate"><span class="pre">__PRETTY_FUNCTION__</span></code> are not string literals.
They are defined as static character arrays, so they cannot be implicitly
concatentated with string literals. For example, <code class="docutils literal notranslate"><span class="pre">printf(__func__</span> <span class="pre">&quot;:</span> <span class="pre">%d&quot;,</span>
<span class="pre">123);</span></code> will not compile.</p>
</div>
<div class="section" id="tokenization-in-python">
<h3>Tokenization in Python<a class="headerlink" href="#tokenization-in-python" title="Permalink to this headline">¶</a></h3>
<p>The Python <code class="docutils literal notranslate"><span class="pre">pw_tokenizer.encode</span></code> module has limited support for encoding
tokenized messages with the <code class="docutils literal notranslate"><span class="pre">encode_token_and_args</span></code> function.</p>
<dl class="function">
<dt id="pw_tokenizer.encode.encode_token_and_args">
<code class="sig-prename descclassname">pw_tokenizer.encode.</code><code class="sig-name descname">encode_token_and_args</code><span class="sig-paren">(</span><em class="sig-param">token: int, *args: Union[int, float, bytes, str]</em><span class="sig-paren">)</span> &#x2192; bytes<a class="headerlink" href="#pw_tokenizer.encode.encode_token_and_args" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a tokenized message given its token and arguments.</p>
<p>This function assumes that the token represents a format string with
conversion specifiers that correspond with the provided argument types.
Currently, only 32-bit integers are supported.</p>
</dd></dl>

</div>
<div class="section" id="encoding">
<h3>Encoding<a class="headerlink" href="#encoding" title="Permalink to this headline">¶</a></h3>
<p>The token is a 32-bit hash calculated during compilation. The string is encoded
little-endian with the token followed by arguments, if any. For example, the
31-byte string <code class="docutils literal notranslate"><span class="pre">You</span> <span class="pre">can</span> <span class="pre">go</span> <span class="pre">about</span> <span class="pre">your</span> <span class="pre">business.</span></code> hashes to 0xdac9a244.
This is encoded as 4 bytes: <code class="docutils literal notranslate"><span class="pre">44</span> <span class="pre">a2</span> <span class="pre">c9</span> <span class="pre">da</span></code>.</p>
<p>Arguments are encoded as follows:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Integers</strong>  (1–10 bytes) –
<a class="reference external" href="https://developers.google.com/protocol-buffers/docs/encoding#signed-integers">ZagZag and varint encoded</a>,
similarly to Protocol Buffers. Smaller values take fewer bytes.</p></li>
<li><p><strong>Floating point numbers</strong> (4 bytes) – Single precision floating point.</p></li>
<li><p><strong>Strings</strong> (1–128 bytes) – Length byte followed by the string contents.
The top bit of the length whether the string was truncated or
not. The remaining 7 bits encode the string length, with a maximum of 127
bytes.</p></li>
</ul>
</div></blockquote>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><code class="docutils literal notranslate"><span class="pre">%s</span></code> arguments can quickly fill a tokenization buffer. Keep <code class="docutils literal notranslate"><span class="pre">%s</span></code> arguments
short or avoid encoding them as strings (e.g. encode an enum as an integer
instead of a string). See also <a class="reference internal" href="#tokenized-strings-as-s-arguments">Tokenized strings as %s arguments</a>.</p>
</div>
</div>
<div class="section" id="token-generation-fixed-length-hashing-at-compile-time">
<h3>Token generation: fixed length hashing at compile time<a class="headerlink" href="#token-generation-fixed-length-hashing-at-compile-time" title="Permalink to this headline">¶</a></h3>
<p>String tokens are generated using a modified version of the x65599 hash used by
the SDBM project. All hashing is done at compile time.</p>
<p>In C code, strings are hashed with a preprocessor macro. For compatibility with
macros, the hash must be limited to a fixed maximum number of characters. This
value is set by <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZER_CFG_HASH_LENGTH</span></code>.</p>
<p>Increasing <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZER_CFG_HASH_LENGTH</span></code> increases the compilation time for C
due to the complexity of the hashing macros. C++ macros use a constexpr
function instead of a macro, so the compilation time impact is minimal. Projects
primarily in C++ may use a large value for <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZER_CFG_HASH_LENGTH</span></code>
(perhaps even <code class="docutils literal notranslate"><span class="pre">std::numeric_limits&lt;size_t&gt;::max()</span></code>).</p>
</div>
<div class="section" id="tokenization-domains">
<h3>Tokenization domains<a class="headerlink" href="#tokenization-domains" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> supports having multiple tokenization domains. Strings from
each tokenization domain are stored in separate sections in the ELF file. This
allows projects to keep tokens from different sources separate. Potential use
cases include the following:</p>
<ul class="simple">
<li><p>Keep large sets of tokenized strings separate to avoid collisions.</p></li>
<li><p>Create a separate database for a small number of strings that use truncated
tokens, for example only 10 or 16 bits instead of the full 32 bits.</p></li>
</ul>
<p>Strings are tokenized by default into the “default” domain. For many projects,
a single tokenization domain is sufficient, so no additional configuration is
required.</p>
<p>To support other multiple domains, add a <code class="docutils literal notranslate"><span class="pre">pw_tokenized.&lt;new</span> <span class="pre">domain</span> <span class="pre">name&gt;</span></code>
linker section, as described in <code class="docutils literal notranslate"><span class="pre">pw_tokenizer_linker_sections.ld</span></code>. Strings are
tokenized into a domain by providing the domain name as a string literal to the
<code class="docutils literal notranslate"><span class="pre">*_DOMAIN</span></code> versions of the tokenization macros. Domain names must be comprised
of alphanumeric characters and underscores; spaces and special characters are
not permitted.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Tokenizes this string to the &quot;default&quot; domain.</span>
<span class="n">PW_TOKENIZE_STRING</span><span class="p">(</span><span class="s">&quot;Hello, world!&quot;</span><span class="p">);</span>

<span class="c1">// Tokenizes this string to the &quot;my_custom_domain&quot; domain.</span>
<span class="n">PW_TOKENIZE_STRING_DOMAIN</span><span class="p">(</span><span class="s">&quot;my_custom_domain&quot;</span><span class="p">,</span> <span class="s">&quot;Hello, world!&quot;</span><span class="p">);</span>
</pre></div>
</div>
<p>The database and detokenization command line tools default to reading from the
default domain. The domain may be specified for ELF files by appending
<code class="docutils literal notranslate"><span class="pre">#DOMAIN_NAME</span></code> to the file path. Use <code class="docutils literal notranslate"><span class="pre">#.*</span></code> to read from all domains. For
example, the following reads strings in <code class="docutils literal notranslate"><span class="pre">some_domain</span></code> from <code class="docutils literal notranslate"><span class="pre">my_image.elf</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./database.py create --database my_db.csv path/to/my_image.elf#some_domain
</pre></div>
</div>
<p>See <a class="reference internal" href="#managing-token-databases">Managing token databases</a> for information about the <code class="docutils literal notranslate"><span class="pre">database.py</span></code>
command line tool.</p>
</div>
</div>
<div class="section" id="token-databases">
<h2>Token databases<a class="headerlink" href="#token-databases" title="Permalink to this headline">¶</a></h2>
<p>Token databases store a mapping of tokens to the strings they represent. An ELF
file can be used as a token database, but it only contains the strings for its
exact build. A token database file aggregates tokens from multiple ELF files, so
that a single database can decode tokenized strings from any known ELF.</p>
<p>Token databases contain the token, removal date (if any), and string for each
tokenized string. Two token database formats are supported: CSV and binary.</p>
<div class="section" id="csv-database-format">
<h3>CSV database format<a class="headerlink" href="#csv-database-format" title="Permalink to this headline">¶</a></h3>
<p>The CSV database format has three columns: the token in hexadecimal, the removal
date (if any) in year-month-day format, and the string literal, surrounded by
quotes. Quote characters within the string are represented as two quote
characters.</p>
<p>This example database contains six strings, three of which have removal dates.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">141</span><span class="n">c35d5</span><span class="p">,</span>          <span class="p">,</span><span class="s2">&quot;The answer: &quot;&quot;</span><span class="si">%s</span><span class="s2">&quot;&quot;&quot;</span>
<span class="mf">2e668</span><span class="n">cd6</span><span class="p">,</span><span class="mi">2019</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">25</span><span class="p">,</span><span class="s2">&quot;Jello, world!&quot;</span>
<span class="mi">7</span><span class="n">b940e2a</span><span class="p">,</span>          <span class="p">,</span><span class="s2">&quot;Hello </span><span class="si">%s</span><span class="s2">! </span><span class="si">%hd</span><span class="s2"> </span><span class="si">%e</span><span class="s2">&quot;</span>
<span class="mi">851</span><span class="n">beeb6</span><span class="p">,</span>          <span class="p">,</span><span class="s2">&quot;</span><span class="si">%u</span><span class="s2"> </span><span class="si">%d</span><span class="s2">&quot;</span>
<span class="mi">881436</span><span class="n">a0</span><span class="p">,</span><span class="mi">2020</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">01</span><span class="p">,</span><span class="s2">&quot;The answer is: </span><span class="si">%s</span><span class="s2">&quot;</span>
<span class="n">e13b0f94</span><span class="p">,</span><span class="mi">2020</span><span class="o">-</span><span class="mi">04</span><span class="o">-</span><span class="mi">01</span><span class="p">,</span><span class="s2">&quot;%llu&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="binary-database-format">
<h3>Binary database format<a class="headerlink" href="#binary-database-format" title="Permalink to this headline">¶</a></h3>
<p>The binary database format is comprised of a 16-byte header followed by a series
of 8-byte entries. Each entry stores the token and the removal date, which is
0xFFFFFFFF if there is none. The string literals are stored next in the same
order as the entries. Strings are stored with null terminators. See
<a class="reference external" href="https://pigweed.googlesource.com/pigweed/pigweed/+/refs/heads/master/pw_tokenizer/public/pw_tokenizer/token_database.h">token_database.h</a>
for full details.</p>
<p>The binary form of the CSV database is shown below. It contains the same
information, but in a more compact and easily processed form. It takes 141 B
compared with the CSV database’s 211 B.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[header]
0x00: 454b4f54 0000534e  TOKENS..
0x08: 00000006 00000000  ........

[entries]
0x10: 141c35d5 ffffffff  .5......
0x18: 2e668cd6 07e30c19  ..f.....
0x20: 7b940e2a ffffffff  *..{....
0x28: 851beeb6 ffffffff  ........
0x30: 881436a0 07e40101  .6......
0x38: e13b0f94 07e40401  ..;.....

[string table]
0x40: 54 68 65 20 61 6e 73 77 65 72 3a 20 22 25 73 22  The answer: &quot;%s&quot;
0x50: 00 4a 65 6c 6c 6f 2c 20 77 6f 72 6c 64 21 00 48  .Jello, world!.H
0x60: 65 6c 6c 6f 20 25 73 21 20 25 68 64 20 25 65 00  ello %s! %hd %e.
0x70: 25 75 20 25 64 00 54 68 65 20 61 6e 73 77 65 72  %u %d.The answer
0x80: 20 69 73 3a 20 25 73 00 25 6c 6c 75 00            is: %s.%llu.
</pre></div>
</div>
</div>
<div class="section" id="managing-token-databases">
<h3>Managing token databases<a class="headerlink" href="#managing-token-databases" title="Permalink to this headline">¶</a></h3>
<p>Token databases are managed with the <code class="docutils literal notranslate"><span class="pre">database.py</span></code> script. This script can be
used to extract tokens from compilation artifacts and manage database files.
Invoke <code class="docutils literal notranslate"><span class="pre">database.py</span></code> with <code class="docutils literal notranslate"><span class="pre">-h</span></code> for full usage information.</p>
<p>An example ELF file with tokenized logs is provided at
<code class="docutils literal notranslate"><span class="pre">pw_tokenizer/py/example_binary_with_tokenized_strings.elf</span></code>. You can use that
file to experiment with the <code class="docutils literal notranslate"><span class="pre">database.py</span></code> commands.</p>
<div class="section" id="create-a-database">
<h4>Create a database<a class="headerlink" href="#create-a-database" title="Permalink to this headline">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">create</span></code> command makes a new token database from ELF files (.elf, .o, .so,
etc.), archives (.a), or existing token databases (CSV or binary).</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./database.py create --database DATABASE_NAME ELF_OR_DATABASE_FILE...
</pre></div>
</div>
<p>Two database formats are supported: CSV and binary. Provide <code class="docutils literal notranslate"><span class="pre">--type</span> <span class="pre">binary</span></code> to
<code class="docutils literal notranslate"><span class="pre">create</span></code> to generate a binary database instead of the default CSV. CSV
databases are great for checking into a source control or for human review.
Binary databases are more compact and simpler to parse. The C++ detokenizer
library only supports binary databases currently.</p>
</div>
<div class="section" id="update-a-database">
<h4>Update a database<a class="headerlink" href="#update-a-database" title="Permalink to this headline">¶</a></h4>
<p>As new tokenized strings are added, update the database with the <code class="docutils literal notranslate"><span class="pre">add</span></code>
command.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./database.py add --database DATABASE_NAME ELF_OR_DATABASE_FILE...
</pre></div>
</div>
<p>A CSV token database can be checked into a source repository and updated as code
changes are made. The build system can invoke <code class="docutils literal notranslate"><span class="pre">database.py</span></code> to update the
database after each build.</p>
</div>
<div class="section" id="gn-integration">
<h4>GN integration<a class="headerlink" href="#gn-integration" title="Permalink to this headline">¶</a></h4>
<p>Token databases may be updated or created as part of a GN build. The
<code class="docutils literal notranslate"><span class="pre">pw_tokenizer_database</span></code> template provided by <code class="docutils literal notranslate"><span class="pre">dir_pw_tokenizer/database.gni</span></code>
automatically updates an in-source tokenized strings database or creates a new
database with artifacts from one or more GN targets or other database files.</p>
<p>To create a new database, set the <code class="docutils literal notranslate"><span class="pre">create</span></code> variable to the desired database
type (<code class="docutils literal notranslate"><span class="pre">&quot;csv&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;binary&quot;</span></code>). The database will be created in the output
directory. To update an existing database, provide the path to the database with
the <code class="docutils literal notranslate"><span class="pre">database</span></code> variable.</p>
<p>Each database in the source tree can only be updated from a single
<code class="docutils literal notranslate"><span class="pre">pw_tokenizer_database</span></code> rule. Updating the same database in multiple rules
results in <code class="docutils literal notranslate"><span class="pre">Duplicate</span> <span class="pre">output</span> <span class="pre">file</span></code> GN errors or <code class="docutils literal notranslate"><span class="pre">multiple</span> <span class="pre">rules</span> <span class="pre">generate</span>
<span class="pre">&lt;file&gt;</span></code> Ninja errors. To avoid these errors, <code class="docutils literal notranslate"><span class="pre">pw_tokenizer_database</span></code> rules
should be defined in the default toolchain, and the input targets should be
referenced with specific toolchains.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># gn-format disable</span>
<span class="n">import</span><span class="p">(</span><span class="s2">&quot;//build_overrides/pigweed.gni&quot;</span><span class="p">)</span>

<span class="n">import</span><span class="p">(</span><span class="s2">&quot;$dir_pw_tokenizer/database.gni&quot;</span><span class="p">)</span>

<span class="n">pw_tokenizer_database</span><span class="p">(</span><span class="s2">&quot;my_database&quot;</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">database</span> <span class="o">=</span> <span class="s2">&quot;database_in_the_source_tree.csv&quot;</span>
  <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span> <span class="s2">&quot;//firmware/image:foo(//targets/my_board:some_toolchain)&quot;</span> <span class="p">]</span>
  <span class="n">input_databases</span> <span class="o">=</span> <span class="p">[</span> <span class="s2">&quot;other_database.csv&quot;</span> <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="detokenization">
<h2>Detokenization<a class="headerlink" href="#detokenization" title="Permalink to this headline">¶</a></h2>
<p>Detokenization is the process of expanding a token to the string it represents
and decoding its arguments. This module provides Python and C++ detokenization
libraries.</p>
<p><strong>Example: decoding tokenized logs</strong></p>
<p>A project might tokenize its log messages with the <a class="reference internal" href="#base64-format">Base64 format</a>. Consider
the following log file, which has four tokenized logs and one plain text log:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>20200229 14:38:58 INF $HL2VHA==
20200229 14:39:00 DBG $5IhTKg==
20200229 14:39:20 DBG Crunching numbers to calculate probability of success
20200229 14:39:21 INF $EgFj8lVVAUI=
20200229 14:39:23 ERR $DFRDNwlOT1RfUkVBRFk=
</pre></div>
</div>
<p>The project’s log strings are stored in a database like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span><span class="n">c95bd1c</span><span class="p">,</span>          <span class="p">,</span><span class="s2">&quot;Initiating retrieval process for recovery object&quot;</span>
<span class="mi">2</span><span class="n">a5388e4</span><span class="p">,</span>          <span class="p">,</span><span class="s2">&quot;Determining optimal approach and coordinating vectors&quot;</span>
<span class="mi">3743540</span><span class="n">c</span><span class="p">,</span>          <span class="p">,</span><span class="s2">&quot;Recovery object retrieval failed with status </span><span class="si">%s</span><span class="s2">&quot;</span>
<span class="n">f2630112</span><span class="p">,</span>          <span class="p">,</span><span class="s2">&quot;Calculated acceptable probability of success (</span><span class="si">%.2f%%</span><span class="s2">)&quot;</span>
</pre></div>
</div>
<p>Using the detokenizing tools with the database, the logs can be decoded:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>20200229 14:38:58 INF Initiating retrieval process for recovery object
20200229 14:39:00 DBG Determining optimal algorithm and coordinating approach vectors
20200229 14:39:20 DBG Crunching numbers to calculate probability of success
20200229 14:39:21 INF Calculated acceptable probability of success (32.33%)
20200229 14:39:23 ERR Recovery object retrieval failed with status NOT_READY
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This example uses the <a class="reference internal" href="#base64-format">Base64 format</a>, which occupies about 4/3 (133%) as
much space as the default binary format when encoded. For projects that wish
to interleave tokenized with plain text, using Base64 is a worthwhile
tradeoff.</p>
</div>
<div class="section" id="python">
<h3>Python<a class="headerlink" href="#python" title="Permalink to this headline">¶</a></h3>
<p>To detokenize in Python, import <code class="docutils literal notranslate"><span class="pre">Detokenizer</span></code> from the <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code>
package, and instantiate it with paths to token databases or ELF files.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pw_tokenizer</span>

<span class="n">detokenizer</span> <span class="o">=</span> <span class="n">pw_tokenizer</span><span class="o">.</span><span class="n">Detokenizer</span><span class="p">(</span><span class="s1">&#39;path/to/database.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;other/path.elf&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">process_log_message</span><span class="p">(</span><span class="n">log_message</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">detokenizer</span><span class="o">.</span><span class="n">detokenize</span><span class="p">(</span><span class="n">log_message</span><span class="o">.</span><span class="n">payload</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_log</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">result</span><span class="p">))</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> package also provides the <code class="docutils literal notranslate"><span class="pre">AutoUpdatingDetokenizer</span></code>
class, which can be used in place of the standard <code class="docutils literal notranslate"><span class="pre">Detokenizer</span></code>. This class
monitors database files for changes and automatically reloads them when they
change. This is helpful for long-running tools that use detokenization.</p>
</div>
<div class="section" id="c">
<h3>C++<a class="headerlink" href="#c" title="Permalink to this headline">¶</a></h3>
<p>The C++ detokenization libraries can be used in C++ or any language that can
call into C++ with a C-linkage wrapper, such as Java or Rust. A reference
Java Native Interface (JNI) implementation is provided.</p>
<p>The C++ detokenization library uses binary-format token databases (created with
<code class="docutils literal notranslate"><span class="pre">database.py</span> <span class="pre">create</span> <span class="pre">--type</span> <span class="pre">binary</span></code>). Read a binary format database from a
file or include it in the source code. Pass the database array to
<code class="docutils literal notranslate"><span class="pre">TokenDatabase::Create</span></code>, and construct a detokenizer.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Detokenizer</span> <span class="nf">detokenizer</span><span class="p">(</span><span class="n">TokenDatabase</span><span class="o">::</span><span class="n">Create</span><span class="p">(</span><span class="n">token_database_array</span><span class="p">));</span>

<span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">ProcessLog</span><span class="p">(</span><span class="n">span</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span> <span class="n">log_data</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">detokenizer</span><span class="p">.</span><span class="n">Detokenize</span><span class="p">(</span><span class="n">log_data</span><span class="p">).</span><span class="n">BestString</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">TokenDatabase</span></code> class verifies that its data is valid before using it. If
it is invalid, the <code class="docutils literal notranslate"><span class="pre">TokenDatabase::Create</span></code> returns an empty database for which
<code class="docutils literal notranslate"><span class="pre">ok()</span></code> returns false. If the token database is included in the source code,
this check can be done at compile time.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// This line fails to compile with a static_assert if the database is invalid.</span>
<span class="k">constexpr</span> <span class="n">TokenDatabase</span> <span class="n">kDefaultDatabase</span> <span class="o">=</span>  <span class="n">TokenDatabase</span><span class="o">::</span><span class="n">Create</span><span class="o">&lt;</span><span class="n">kData</span><span class="o">&gt;</span><span class="p">();</span>

<span class="n">Detokenizer</span> <span class="nf">OpenDatabase</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">string_view</span> <span class="n">path</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">ReadWholeFile</span><span class="p">(</span><span class="n">path</span><span class="p">);</span>

  <span class="n">TokenDatabase</span> <span class="n">database</span> <span class="o">=</span> <span class="n">TokenDatabase</span><span class="o">::</span><span class="n">Create</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>

  <span class="c1">// This checks if the file contained a valid database. It is safe to use a</span>
  <span class="c1">// TokenDatabase that failed to load (it will be empty), but it may be</span>
  <span class="c1">// desirable to provide a default database or otherwise handle the error.</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">database</span><span class="p">.</span><span class="n">ok</span><span class="p">())</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">Detokenizer</span><span class="p">(</span><span class="n">database</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="n">Detokenizer</span><span class="p">(</span><span class="n">kDefaultDatabase</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="base64-format">
<h2>Base64 format<a class="headerlink" href="#base64-format" title="Permalink to this headline">¶</a></h2>
<p>The tokenizer encodes messages to a compact binary representation. Applications
may desire a textual representation of tokenized strings. This makes it easy to
use tokenized messages alongside plain text messages, but comes at a small
efficiency cost: encoded Base64 messages occupy about 4/3 (133%) as much memory
as binary messages.</p>
<p>The Base64 format is comprised of a <code class="docutils literal notranslate"><span class="pre">$</span></code> character followed by the
Base64-encoded contents of the tokenized message. For example, consider
tokenizing the string <code class="docutils literal notranslate"><span class="pre">This</span> <span class="pre">is</span> <span class="pre">an</span> <span class="pre">example:</span> <span class="pre">%d!</span></code> with the argument -1. The
string’s token is 0x4b016e66.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Source code: PW_TOKENIZE_TO_GLOBAL_HANDLER(&quot;This is an example: %d!&quot;, -1);

 Plain text: This is an example: -1! [23 bytes]

     Binary: 66 6e 01 4b 01          [ 5 bytes]

     Base64: $Zm4BSwE=               [ 9 bytes]
</pre></div>
</div>
<div class="section" id="id1">
<h3>Encoding<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>To encode with the Base64 format, add a call to
<code class="docutils literal notranslate"><span class="pre">pw::tokenizer::PrefixedBase64Encode</span></code> or <code class="docutils literal notranslate"><span class="pre">pw_tokenizer_PrefixedBase64Encode</span></code>
in the tokenizer handler function. For example,</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span> <span class="nf">pw_tokenizer_HandleEncodedMessage</span><span class="p">(</span><span class="k">const</span> <span class="kt">uint8_t</span> <span class="n">encoded_message</span><span class="p">[],</span>
                                      <span class="kt">size_t</span> <span class="n">size_bytes</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">char</span> <span class="n">base64_buffer</span><span class="p">[</span><span class="mi">64</span><span class="p">];</span>
  <span class="kt">size_t</span> <span class="n">base64_size</span> <span class="o">=</span> <span class="n">pw</span><span class="o">::</span><span class="n">tokenizer</span><span class="o">::</span><span class="n">PrefixedBase64Encode</span><span class="p">(</span>
      <span class="n">pw</span><span class="o">::</span><span class="n">span</span><span class="p">(</span><span class="n">encoded_message</span><span class="p">,</span> <span class="n">size_bytes</span><span class="p">),</span> <span class="n">base64_buffer</span><span class="p">);</span>

  <span class="n">TransmitLogMessage</span><span class="p">(</span><span class="n">base64_buffer</span><span class="p">,</span> <span class="n">base64_size</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="decoding">
<h3>Decoding<a class="headerlink" href="#decoding" title="Permalink to this headline">¶</a></h3>
<p>Base64 decoding and detokenizing is supported in the Python detokenizer through
the <code class="docutils literal notranslate"><span class="pre">detokenize_base64</span></code> and related functions.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The Python detokenization tools support recursive detokenization for prefixed
Base64 text. Tokenized strings found in detokenized text are detokenized, so
prefixed Base64 messages can be passed as <code class="docutils literal notranslate"><span class="pre">%s</span></code> arguments.</p>
<p>For example, the tokenized string for “Wow!” is <code class="docutils literal notranslate"><span class="pre">$RhYjmQ==</span></code>. This could be
passed as an argument to the printf-style string <code class="docutils literal notranslate"><span class="pre">Nested</span> <span class="pre">message:</span> <span class="pre">%s</span></code>, which
encodes to <code class="docutils literal notranslate"><span class="pre">$pEVTYQkkUmhZam1RPT0=</span></code>. The detokenizer would decode the message
as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&quot;$pEVTYQkkUmhZam1RPT0=&quot; → &quot;Nested message: $RhYjmQ==&quot; → &quot;Nested message: Wow!&quot;
</pre></div>
</div>
</div>
<p>Base64 decoding is supported in C++ or C with the
<code class="docutils literal notranslate"><span class="pre">pw::tokenizer::PrefixedBase64Decode</span></code> or <code class="docutils literal notranslate"><span class="pre">pw_tokenizer_PrefixedBase64Decode</span></code>
functions.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span> <span class="nf">pw_tokenizer_HandleEncodedMessage</span><span class="p">(</span><span class="k">const</span> <span class="kt">uint8_t</span> <span class="n">encoded_message</span><span class="p">[],</span>
                                      <span class="kt">size_t</span> <span class="n">size_bytes</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">char</span> <span class="n">base64_buffer</span><span class="p">[</span><span class="mi">64</span><span class="p">];</span>
  <span class="kt">size_t</span> <span class="n">base64_size</span> <span class="o">=</span> <span class="n">pw</span><span class="o">::</span><span class="n">tokenizer</span><span class="o">::</span><span class="n">PrefixedBase64Encode</span><span class="p">(</span>
      <span class="n">pw</span><span class="o">::</span><span class="n">span</span><span class="p">(</span><span class="n">encoded_message</span><span class="p">,</span> <span class="n">size_bytes</span><span class="p">),</span> <span class="n">base64_buffer</span><span class="p">);</span>

  <span class="n">TransmitLogMessage</span><span class="p">(</span><span class="n">base64_buffer</span><span class="p">,</span> <span class="n">base64_size</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="section" id="command-line-utilities">
<h4>Command line utilities<a class="headerlink" href="#command-line-utilities" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> provides two standalone command line utilities for detokenizing
Base64-encoded tokenized strings.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">detokenize.py</span></code> – Detokenizes Base64-encoded strings in files or from
stdin.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">detokenize_serial.py</span></code> – Detokenizes Base64-encoded strings from a
connected serial device.</p></li>
</ul>
<p>If the <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> Python package is installed, these tools may be executed
as runnable modules. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Detokenize Base64-encoded strings in a file</span>
<span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">pw_tokenizer</span><span class="o">.</span><span class="n">detokenize</span> <span class="o">-</span><span class="n">i</span> <span class="n">input_file</span><span class="o">.</span><span class="n">txt</span>

<span class="c1"># Detokenize Base64-encoded strings in output from a serial device</span>
<span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">pw_tokenizer</span><span class="o">.</span><span class="n">detokenize_serial</span> <span class="o">--</span><span class="n">device</span> <span class="o">/</span><span class="n">dev</span><span class="o">/</span><span class="n">ttyACM0</span>
</pre></div>
</div>
<p>See the <code class="docutils literal notranslate"><span class="pre">--help</span></code> options for these tools for full usage information.</p>
</div>
</div>
</div>
<div class="section" id="deployment-war-story">
<h2>Deployment war story<a class="headerlink" href="#deployment-war-story" title="Permalink to this headline">¶</a></h2>
<p>The tokenizer module was developed to bring tokenized logging to an
in-development product. The product already had an established text-based
logging system. Deploying tokenization was straightforward and had substantial
benefits.</p>
<div class="section" id="results">
<h3>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>Log contents shrunk by over 50%, even with Base64 encoding.</p>
<ul>
<li><p>Significant size savings for encoded logs, even using the less-efficient
Base64 encoding required for compatibility with the existing log system.</p></li>
<li><p>Freed valuable communication bandwidth.</p></li>
<li><p>Allowed storing many more logs in crash dumps.</p></li>
</ul>
</li>
<li><p>Substantial flash savings.</p>
<ul>
<li><p>Reduced the size firmware images by up to 18%.</p></li>
</ul>
</li>
<li><p>Simpler logging code.</p>
<ul>
<li><p>Removed CPU-heavy <code class="docutils literal notranslate"><span class="pre">snprintf</span></code> calls.</p></li>
<li><p>Removed complex code for forwarding log arguments to a low-priority task.</p></li>
</ul>
</li>
</ul>
</div></blockquote>
<p>This section describes the tokenizer deployment process and highlights key
insights.</p>
</div>
<div class="section" id="firmware-deployment">
<h3>Firmware deployment<a class="headerlink" href="#firmware-deployment" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>In the project’s logging macro, calls to the underlying logging function
were replaced with a <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_GLOBAL_HANDLER_WITH_PAYLOAD</span></code>
invocation.</p></li>
<li><p>The log level was passed as the payload argument to facilitate runtime log
level control.</p></li>
<li><p>For this project, it was necessary to encode the log messages as text. In
<code class="docutils literal notranslate"><span class="pre">pw_tokenizer_HandleEncodedMessageWithPayload</span></code>, the log messages were
encoded in the $-prefixed <a class="reference internal" href="#base64-format">Base64 format</a>, then dispatched as normal log
messages.</p></li>
<li><p>Asserts were tokenized using <code class="docutils literal notranslate"><span class="pre">PW_TOKENIZE_TO_CALLBACK</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>Do not encode line numbers in tokenized strings. This results in a huge
number of lines being added to the database, since every time code moves,
new strings are tokenized. If line numbers are desired in a tokenized
string, add a <code class="docutils literal notranslate"><span class="pre">&quot;%d&quot;</span></code> to the string and pass <code class="docutils literal notranslate"><span class="pre">__LINE__</span></code> as an argument.</p>
</div>
</div>
<div class="section" id="database-management">
<h3>Database management<a class="headerlink" href="#database-management" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>The token database was stored as a CSV file in the project’s Git repo.</p></li>
<li><p>The token database was automatically updated as part of the build, and
developers were expected to check in the database changes alongside their
code changes.</p></li>
<li><p>A presubmit check verified that all strings added by a change were added to
the token database.</p></li>
<li><p>The token database included logs and asserts for all firmware images in the
project.</p></li>
<li><p>No strings were purged from the token database.</p></li>
</ul>
</div></blockquote>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Merge conflicts may be a frequent occurrence with an in-source database. If
the database is in-source, make sure there is a simple script to resolve any
merge conflicts. The script could either keep both sets of lines or discard
local changes and regenerate the database.</p>
</div>
</div>
<div class="section" id="decoding-tooling-deployment">
<h3>Decoding tooling deployment<a class="headerlink" href="#decoding-tooling-deployment" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul>
<li><p>The Python detokenizer in <code class="docutils literal notranslate"><span class="pre">pw_tokenizer</span></code> was deployed to two places:</p>
<blockquote>
<div><ul class="simple">
<li><p>Product-specific Python command line tools, using
<code class="docutils literal notranslate"><span class="pre">pw_tokenizer.Detokenizer</span></code>.</p></li>
<li><p>Standalone script for decoding prefixed Base64 tokens in files or
live output (e.g. from <code class="docutils literal notranslate"><span class="pre">adb</span></code>), using <code class="docutils literal notranslate"><span class="pre">detokenize.py</span></code>’s command line
interface.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>The C++ detokenizer library was deployed to two Android apps with a Java
Native Interface (JNI) layer.</p>
<blockquote>
<div><ul class="simple">
<li><p>The binary token database was included as a raw resource in the APK.</p></li>
<li><p>In one app, the built-in token database could be overridden by copying a
file to the phone.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Make the tokenized logging tools simple to use for your project.</p>
<ul class="simple">
<li><p>Provide simple wrapper shell scripts that fill in arguments for the
project. For example, point <code class="docutils literal notranslate"><span class="pre">detokenize.py</span></code> to the project’s token
databases.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">pw_tokenizer.AutoReloadingDetokenizer</span></code> to decode in
continuously-running tools, so that users don’t have to restart the tool
when the token database updates.</p></li>
<li><p>Integrate detokenization everywhere it is needed. Integrating the tools
takes just a few lines of code, and token databases can be embedded in
APKs or binaries.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="limitations-and-future-work">
<h2>Limitations and future work<a class="headerlink" href="#limitations-and-future-work" title="Permalink to this headline">¶</a></h2>
<div class="section" id="gcc-bug-tokenization-in-template-functions">
<h3>GCC bug: tokenization in template functions<a class="headerlink" href="#gcc-bug-tokenization-in-template-functions" title="Permalink to this headline">¶</a></h3>
<p>GCC incorrectly ignores the section attribute for template
<a class="reference external" href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=70435">functions</a> and
<a class="reference external" href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=88061">variables</a>. Due to this
bug, tokenized strings in template functions may be emitted into <code class="docutils literal notranslate"><span class="pre">.rodata</span></code>
instead of the special tokenized string section. This causes two problems:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Tokenized strings will not be discovered by the token database tools.</p></li>
<li><p>Tokenized strings may not be removed from the final binary.</p></li>
</ol>
</div></blockquote>
<p>clang does <strong>not</strong> have this issue! Use clang to avoid this.</p>
<p>It is possible to work around this bug in GCC. One approach would be to tag
format strings so that the database tools can find them in <code class="docutils literal notranslate"><span class="pre">.rodata</span></code>. Then, to
remove the strings, compile two binaries: one metadata binary with all tokenized
strings and a second, final binary that removes the strings. The strings could
be removed by providing the appropriate linker flags or by removing the <code class="docutils literal notranslate"><span class="pre">used</span></code>
attribute from the tokenized string character array declaration.</p>
</div>
<div class="section" id="bit-tokenization">
<h3>64-bit tokenization<a class="headerlink" href="#bit-tokenization" title="Permalink to this headline">¶</a></h3>
<p>The Python and C++ detokenizing libraries currently assume that strings were
tokenized on a system with 32-bit <code class="docutils literal notranslate"><span class="pre">long</span></code>, <code class="docutils literal notranslate"><span class="pre">size_t</span></code>, <code class="docutils literal notranslate"><span class="pre">intptr_t</span></code>, and
<code class="docutils literal notranslate"><span class="pre">ptrdiff_t</span></code>. Decoding may not work correctly for these types if a 64-bit
device performed the tokenization.</p>
<p>Supporting detokenization of strings tokenized on 64-bit targets would be
simple. This could be done by adding an option to switch the 32-bit types to
64-bit. The tokenizer stores the sizes of these types in the
<code class="docutils literal notranslate"><span class="pre">.pw_tokenizer_info</span></code> ELF section, so the sizes of these types can be verified
by checking the ELF file, if necessary.</p>
</div>
<div class="section" id="tokenization-in-headers">
<h3>Tokenization in headers<a class="headerlink" href="#tokenization-in-headers" title="Permalink to this headline">¶</a></h3>
<p>Tokenizing code in header files (inline functions or templates) may trigger
warnings such as <code class="docutils literal notranslate"><span class="pre">-Wlto-type-mismatch</span></code> under certain conditions. That
is because tokenization requires declaring a character array for each tokenized
string. If the tokenized string includes macros that change value, the size of
this character array changes, which means the same static variable is defined
with different sizes. It should be safe to suppress these warnings, but, when
possible, code that tokenizes strings with macros that can change value should
be moved to source files rather than headers.</p>
</div>
<div class="section" id="tokenized-strings-as-s-arguments">
<h3>Tokenized strings as <code class="docutils literal notranslate"><span class="pre">%s</span></code> arguments<a class="headerlink" href="#tokenized-strings-as-s-arguments" title="Permalink to this headline">¶</a></h3>
<p>Encoding <code class="docutils literal notranslate"><span class="pre">%s</span></code> string arguments is inefficient, since <code class="docutils literal notranslate"><span class="pre">%s</span></code> strings are
encoded 1:1, with no tokenization. It would be better to send a tokenized string
literal as an integer instead of a string argument, but this is not yet
supported.</p>
<p>A string token could be sent by marking an integer % argument in a way
recognized by the detokenization tools. The detokenizer would expand the
argument to the string represented by the integer.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#define PW_TOKEN_ARG PRIx32 &quot;&lt;PW_TOKEN]&quot;</span>

<span class="k">constexpr</span> <span class="kt">uint32_t</span> <span class="n">answer_token</span> <span class="o">=</span> <span class="n">PW_TOKENIZE_STRING</span><span class="p">(</span><span class="s">&quot;Uh, who is there&quot;</span><span class="p">);</span>

<span class="n">PW_TOKENIZE_TO_GLOBAL_HANDLER</span><span class="p">(</span><span class="s">&quot;Knock knock: %&quot;</span> <span class="n">PW_TOKEN_ARG</span> <span class="s">&quot;?&quot;</span><span class="p">,</span> <span class="n">answer_token</span><span class="p">);</span>
</pre></div>
</div>
<p>Strings with arguments could be encoded to a buffer, but since printf strings
are null-terminated, a binary encoding would not work. These strings can be
prefixed Base64-encoded and sent as <code class="docutils literal notranslate"><span class="pre">%s</span></code> instead. See <a class="reference internal" href="#base64-format">Base64 format</a>.</p>
<p>Another possibility: encode strings with arguments to a <code class="docutils literal notranslate"><span class="pre">uint64_t</span></code> and send
them as an integer. This would be efficient and simple, but only support a small
number of arguments.</p>
</div>
</div>
<div class="section" id="compatibility">
<h2>Compatibility<a class="headerlink" href="#compatibility" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>C11</p></li>
<li><p>C++11</p></li>
<li><p>Python 3</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="dependencies">
<h2>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pw_varint</span></code> module</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pw_preprocessor</span></code> module</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pw_span</span></code> module</p></li>
</ul>
</div></blockquote>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../pw_toolchain/docs.html" class="btn btn-neutral float-right" title="pw_toolchain" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../pw_target_runner/go/docs.html" class="btn btn-neutral float-left" title="Go" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020 The Pigweed Authors

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>